{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vajahatmomin/Retail-Sales-Prediction/blob/main/Retail%20Sales%20Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - ***Retail Sales Prediction***\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member**     - ***MOMIN VAJAHAT***\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied.\n",
        "\n",
        "You are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set. Note that some stores in the dataset were temporarily closed for refurbishment."
      ],
      "metadata": {
        "id": "I14fTxFknvwR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**  https://github.com/vajahatmomin/Retail-Sales-Prediction"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#**Data Description**\n",
        "**Rossmann Stores Data.csv** - historical data including Sales\n",
        "\n",
        "**store.csv** - supplemental information about the stores\n",
        "\n",
        "***Data fields***\n",
        "\n",
        "Most of the fields are self-explanatory. The following are descriptions for those that aren't.\n",
        "\n",
        "* Id - an Id that represents a (Store, Date) duple within the test set\n",
        "* Store - a unique Id for each store\n",
        "* Sales - the turnover for any given day (this is what you are predicting)\n",
        "* Customers - the number of customers on a given day\n",
        "* Open - an indicator for whether the store was open: 0 = closed, 1 = open\n",
        "* StateHoliday - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None\n",
        "* SchoolHoliday - indicates if the (Store, Date) was affected by the closure of public schools\n",
        "* StoreType - differentiates between 4 different store models: a, b, c, d\n",
        "* Assortment - describes an assortment level: a = basic, b = extra, c = extended\n",
        "* CompetitionDistance - distance in meters to the nearest competitor store\n",
        "* CompetitionOpenSince[Month/Year] - gives the approximate year and month of the time the nearest competitor was opened\n",
        "* Promo - indicates whether a store is running a promo on that day\n",
        "* Promo2 - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating\n",
        "* Promo2Since[Year/Week] - describes the year and calendar week when the store started participating in Promo2\n",
        "* PromoInterval - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "import missingno as msno\n",
        "import matplotlib\n",
        "import matplotlib.pylab as pylab\n",
        "\n",
        "%matplotlib inline\n",
        "matplotlib.style.use('ggplot')\n",
        "sns.set_style('white')\n",
        "pylab.rcParams['figure.figsize'] = 8,6\n",
        "\n",
        "import math\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.linear_model import LassoLars\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import ElasticNet"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mounting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ERw70-FPpkqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading Rossman Dataset\n",
        "rossman_df= pd.read_csv('/content/drive/MyDrive/Retail Sales Prediction/vm/Rossmann Stores Data.csv', low_memory= False)\n"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading Store Dataset\n",
        "store_df=pd.read_csv('/content/drive/MyDrive/Retail Sales Prediction/vm/store.csv', low_memory= False)\n"
      ],
      "metadata": {
        "id": "Iq-HsVJqyZuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***Analysing the Rossman Dataset***"
      ],
      "metadata": {
        "id": "-nhJSf-3ymz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rossman_df.head()\n"
      ],
      "metadata": {
        "id": "3O13Z4SeytHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rossman_df.tail()\n"
      ],
      "metadata": {
        "id": "kV6AiTqdyvqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking Information about Dataset**"
      ],
      "metadata": {
        "id": "3fLVtiFvyyig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rossman_df.shape\n"
      ],
      "metadata": {
        "id": "k6WZK2JLy2yH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking info of data as data types and rows and cols\n",
        "rossman_df.info()"
      ],
      "metadata": {
        "id": "VPcsIm-Jy6YE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking Null Values\n",
        "rossman_df.isnull().sum()"
      ],
      "metadata": {
        "id": "sZMsi-4XzA96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary Statastics Of Dataset**"
      ],
      "metadata": {
        "id": "9g9c37sZzDqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Summary Statastics\n",
        "rossman_df.describe()"
      ],
      "metadata": {
        "id": "HXTPyctizH3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#No. Of Stores in the Dataset\n",
        "rossman_df.Store.nunique()"
      ],
      "metadata": {
        "id": "UM1lQsfVzLHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Value_counts of StateHoliday Column\n",
        "rossman_df.StateHoliday.value_counts()"
      ],
      "metadata": {
        "id": "huhwREpwzOxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rossman_df['Date'].min(),'initial')\n",
        "print(rossman_df['Date'].max(),'final')"
      ],
      "metadata": {
        "id": "st6iBOPzzuXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This tells us we have a data of almost 3 years.**\n",
        "\n"
      ],
      "metadata": {
        "id": "fQ72o2WWzykD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract year, month, day and week of year from \"Date\"\n",
        "\n",
        "rossman_df['Date']=pd.to_datetime(rossman_df['Date'])\n",
        "rossman_df['Year'] = rossman_df['Date'].apply(lambda x: x.year)\n",
        "rossman_df['Month'] = rossman_df['Date'].apply(lambda x: x.month)\n",
        "rossman_df['Day'] = rossman_df['Date'].apply(lambda x: x.day)\n",
        "rossman_df['WeekOfYear'] = rossman_df['Date'].apply(lambda x: x.weekofyear)"
      ],
      "metadata": {
        "id": "NMLDCk7rzyDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rossman_df.sort_values(by=['Date','Store'],inplace=True,ascending=[False,True])\n",
        "rossman_df.head(2)"
      ],
      "metadata": {
        "id": "OE8I7yOD0OSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***EDA On Rossman Dataset***\n"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Heatmap of the Rossman Dataset**\n"
      ],
      "metadata": {
        "id": "wAFX_tat0jRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_map = rossman_df[rossman_df.columns].corr()\n",
        "obj = np.array(correlation_map)\n",
        "obj[np.tril_indices_from(obj)] = False\n",
        "fig,ax= plt.subplots()\n",
        "fig.set_size_inches(9,9)\n",
        "sns.heatmap(correlation_map, mask=obj,vmax=.7, square=True,annot=True)"
      ],
      "metadata": {
        "id": "3Dy6sH_VClfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As we can see that in the graph given below that Stores mainly closed on Sunday**\n",
        "\n"
      ],
      "metadata": {
        "id": "nTWkFVPYCp7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='DayOfWeek',hue='Open',data=rossman_df)\n"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Sales Are nearly doubled High When Promo is Running*\n",
        "\n"
      ],
      "metadata": {
        "id": "rZlSd2AfCzm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Impact of promo on sales\n",
        "Promo_sales = pd.DataFrame(rossman_df.groupby('Promo').agg({'Sales':'mean'}))\n",
        "sns.barplot(x=Promo_sales.index, y = Promo_sales['Sales'])"
      ],
      "metadata": {
        "id": "EkPQwaSzC5oN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As We can see that In the month of November and Specially in December Sales is increasing Rapidly every year on the christmas eve.**\n",
        "\n"
      ],
      "metadata": {
        "id": "zl_IegQ3C8GB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.catplot(x=\"Month\" ,y = \"Sales\" , data=rossman_df, kind=\"strip\", aspect=2,height=10)"
      ],
      "metadata": {
        "id": "G_EL7YkZDQUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Value Counts of SchoolHoliday Column\n",
        "rossman_df.SchoolHoliday.value_counts()"
      ],
      "metadata": {
        "id": "qoEjkhkeDJS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As we can see in the Piechart Sales affected by School Holiday is 18% and Mainly Sales aren't afffected by School Holiday**\n",
        "\n"
      ],
      "metadata": {
        "id": "kujuR-WQEZ9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = 'Not-Affected' , 'Affected'\n",
        "sizes = rossman_df.SchoolHoliday.value_counts()\n",
        "colors = ['gold', 'silver']\n",
        "explode = (0.1, 0.0)\n",
        "plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
        "        autopct='%1.1f%%', shadow=True, startangle=180)\n",
        "plt.axis('equal')\n",
        "plt.title(\"Sales Affected by Schoolholiday or Not ?\",fontsize=20)\n",
        "plt.plot()\n",
        "fig=plt.gcf()\n",
        "fig.set_size_inches(6,6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rn2EC61UEd1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Transforming Variable StateHoliday**\n"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rossman_df[\"StateHoliday\"] = rossman_df[\"StateHoliday\"].map({0: 0, \"0\": 0, \"a\": 1, \"b\": 1, \"c\": 1})\n"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rossman_df.StateHoliday.value_counts()\n"
      ],
      "metadata": {
        "id": "NXhAyGUjEp4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As we can see in the Piechart Sales affected by State Holiday is only 3% means Sales aren't afffected by State Holiday**\n",
        "\n"
      ],
      "metadata": {
        "id": "C9pwXcFkEvFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = 'Not-Affected' , 'Affected'\n",
        "sizes = rossman_df.StateHoliday.value_counts()\n",
        "colors = ['orange','green']\n",
        "explode = (0.1, 0.0)\n",
        "plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
        "        autopct='%1.1f%%', shadow=True, startangle=180)\n",
        "plt.axis('equal')\n",
        "plt.title(\"Sales Affected by State holiday or Not ?\",fontsize=20)\n",
        "plt.plot()\n",
        "fig=plt.gcf()\n",
        "fig.set_size_inches(6,6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GrmGaxjBEzYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As Sales isn't much affected by State Holiday so i'm removing this column**\n",
        "\n"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rossman_df.drop('StateHoliday',inplace=True,axis=1)\n"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Histogram Representation of Sales. Here 0 is showing because most of the time store was closed.**\n",
        "\n"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#distribution of sales\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(11, 7)\n",
        "sns.distplot(rossman_df['Sales'], kde = False,bins=40);"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sales vs Customers**\n",
        "\n"
      ],
      "metadata": {
        "id": "6eTdchGxFC8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Analysing the Store Dataset**\n"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.head(5)\n"
      ],
      "metadata": {
        "id": "9ifFI9GEFVqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.tail()\n"
      ],
      "metadata": {
        "id": "7lCruXCzF5IM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking Information about Dataset**\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.shape\n"
      ],
      "metadata": {
        "id": "DB1gBi-kF_15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking info of data as data types and rows and cols\n",
        "store_df.info()"
      ],
      "metadata": {
        "id": "fhr7nhdwGDL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking Null Values\n",
        "store_df.isnull().sum()"
      ],
      "metadata": {
        "id": "hJY1XRJvGGJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Heatmap for null values**\n",
        "\n"
      ],
      "metadata": {
        "id": "hcrvzK-kGJtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating heatmap for null values\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(store_df.isnull(),yticklabels= False, cbar= False, cmap= 'gnuplot')"
      ],
      "metadata": {
        "id": "dO5pAkxQGNuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Distribution Of Different Store Types**\n",
        "\n"
      ],
      "metadata": {
        "id": "-tyQCqHZGQRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = 'a' , 'b' , 'c' , 'd'\n",
        "sizes = store_df.StoreType.value_counts()\n",
        "colors = ['orange', 'green' , 'red' , 'pink']\n",
        "explode = (0.1, 0.0 , 0.15 , 0.0)\n",
        "plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
        "        autopct='%1.1f%%', shadow=True, startangle=180)\n",
        "plt.axis('equal')\n",
        "plt.title(\"Distribution of different StoreTypes\")\n",
        "plt.plot()\n",
        "fig=plt.gcf()\n",
        "fig.set_size_inches(6,6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Pbyb7gLMGUno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Remove features with high percentages of missing values***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**we can see that some features have a high percentage of missing values and they won't be accurate as indicators, so we will remove features with more than 30% missing values.**\n"
      ],
      "metadata": {
        "id": "GV7wHBRUGcql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove features\n",
        "store_df = store_df.drop(['CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear','Promo2SinceWeek',\n",
        "                     'Promo2SinceYear', 'PromoInterval'], axis=1)"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Replace missing values in features with low percentages of missing values**\n"
      ],
      "metadata": {
        "id": "DfjHBp4JGjbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CompetitionDistance is distance in meters to the nearest competitor store\n",
        "# let's first have a look at its distribution\n",
        "\n",
        "sns.distplot(store_df.CompetitionDistance.dropna())\n",
        "plt.title(\"Distributin of Store Competition Distance\")"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***The distribution is right skewed, so we'll replace missing values with the median.***\n",
        " "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# replace missing values in CompetitionDistance with median for the store dataset\n",
        "\n",
        "store_df.CompetitionDistance.fillna(store_df.CompetitionDistance.median(), inplace=True)"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pairplot for Store Dataset**\n",
        "\n"
      ],
      "metadata": {
        "id": "WyzDHCm5G3RE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pairplot for store dataset\n",
        "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
        "pp=sns.pairplot(store_df,hue='StoreType')\n",
        "pp.fig.set_size_inches(10,10);"
      ],
      "metadata": {
        "id": "OqUAF2CxHGGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking stores with their assortment type**\n",
        "\n"
      ],
      "metadata": {
        "id": "AIvltBtjHIte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checking stores with their assortment type \n",
        "sns.set_style(\"whitegrid\")\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(11, 7)\n",
        "store_type=sns.countplot(x='StoreType',hue='Assortment', data=store_df,palette=\"inferno\")\n",
        "\n",
        "for p in store_type.patches:\n",
        "    store_type.annotate(f'\\n{p.get_height()}', (p.get_x()+0.15, p.get_height()),ha='center', va='top', color='white', size=10)"
      ],
      "metadata": {
        "id": "Jwes8PASHNCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We can see that there is not such significant differences in these 3 years in terms of sales.**\n",
        "\n"
      ],
      "metadata": {
        "id": "_h_eBM9hHPNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting year vs sales\n",
        "sns.catplot(x='Year',y='Sales',data=rossman_df, height=4, aspect=4 );"
      ],
      "metadata": {
        "id": "Gfe76o9lHS4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Merging Two Datasets***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.merge(rossman_df, store_df, how='left', on='Store')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "uv10o43sHbdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n"
      ],
      "metadata": {
        "id": "XuneUaCYHeW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***EDA On Merged Dataset***\n"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Heatmap Of Merged Dataset**\n"
      ],
      "metadata": {
        "id": "Z00kWKYcHl2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplots(figsize=(20,12))\n",
        "sns.heatmap(df.corr().abs(), annot=True)\n",
        "plt.savefig(\"heatmap.png\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download('heatmap.png') # this line opens your documents in your pc to save your png"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Avg_Customer_Sales\"] = df.Sales/df.Customers\n"
      ],
      "metadata": {
        "id": "ejH_PvV7Hs7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f, ax = plt.subplots(2, 3, figsize = (20,10))\n",
        "\n",
        "store_df.groupby(\"StoreType\")[\"Store\"].count().plot(kind = \"bar\", ax = ax[0, 0], title = \"Total StoreTypes in the Dataset\")\n",
        "df.groupby(\"StoreType\")[\"Sales\"].sum().plot(kind = \"bar\", ax = ax[0,1], title = \"Total Sales of the StoreTypes\")\n",
        "df.groupby(\"StoreType\")[\"Customers\"].sum().plot(kind = \"bar\", ax = ax[0,2], title = \"Total nr Customers of the StoreTypes\")\n",
        "df.groupby(\"StoreType\")[\"Sales\"].mean().plot(kind = \"bar\", ax = ax[1,0], title = \"Average Sales of StoreTypes\")\n",
        "df.groupby(\"StoreType\")[\"Avg_Customer_Sales\"].mean().plot(kind = \"bar\", ax = ax[1,1], title = \"Average Spending per Customer\")\n",
        "df.groupby(\"StoreType\")[\"Customers\"].mean().plot(kind = \"bar\", ax = ax[1,2], title = \"Average Customers per StoreType\")\n",
        "\n",
        "plt.subplots_adjust(hspace = 0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E7a4TbNvHwZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As we can see from the graphs, the StoreType A has the most stores, sales and customers. However the StoreType D has the best averages spendings per customers. StoreType B, with only 17 stores has the most average customers.**\n",
        "\n"
      ],
      "metadata": {
        "id": "-9quAH1_HzSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Lets go ahead with the promotions***\n"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.catplot(data = df, x =\"Month\", y = \"Sales\", \n",
        "               col = 'Promo', # per store type in cols\n",
        "               hue = 'Promo2',\n",
        "               row = \"Year\"\n",
        "             )\n",
        "# So, of course, if the stores are having promotion the sells are higher.\n",
        "# Overall the store promotions sellings are also higher than the seasionality promotions (Promo2). However I can't see no yearly trend. "
      ],
      "metadata": {
        "id": "nN69G1wXIAa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.catplot(data = df, x = \"DayOfWeek\", y = \"Sales\", hue = \"Promo\")\n"
      ],
      "metadata": {
        "id": "uxQ-qUkTIWKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\"\"So, no promotion in the weekend. However, the sales are very high, if the stores have promotion. \n",
        "The Sales are going crazy on Sunday. No wonder.\"\"\")\n",
        "print(\"There are\", df[(df.Open == 1) & (df.DayOfWeek == 7)].Store.unique().shape[0], \"stores opend on sundays\") "
      ],
      "metadata": {
        "id": "M-UZwgqbIfxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.catplot(data = df, x = \"Month\", y = \"Sales\", col = \"Year\", hue = \"StoreType\")\n",
        "# Yes, we can see a seasonalities, but not trends. The sales stays constantly yearly. \n"
      ],
      "metadata": {
        "id": "qjLiChxAIwre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What about the Competition Distance. What kind of inpact does this have on the sales.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Htg42tX1Im5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.CompetitionDistance.describe()\n",
        "# The obsverations are continous numbers, so we need to convert them into a categories. Lets a create a new variable.\n",
        "df[\"CompetitionDistance_Cat\"] = pd.cut(df[\"CompetitionDistance\"], 5)"
      ],
      "metadata": {
        "id": "FJh4abcIJSbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f, ax = plt.subplots(1,2, figsize = (15,5))\n",
        "\n",
        "df.groupby(by = \"CompetitionDistance_Cat\").Sales.mean().plot(kind = \"bar\", title = \"Average Total Sales by Competition Distance\", ax = ax[0])\n",
        "df.groupby(by = \"CompetitionDistance_Cat\").Customers.mean().plot(kind = \"bar\", title = \"Average Total Customers by Competition Distance\", ax = ax[1])\n",
        "\n",
        "# It is pretty clear. If the competions is very far away, the stores are performing better (sales and customers)"
      ],
      "metadata": {
        "id": "2Anad8ulJV5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Avg_Customer_Sales','CompetitionDistance_Cat'],axis=1,inplace=True)\n"
      ],
      "metadata": {
        "id": "hmtKcGPtJZBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Box plot shows that we have a very high outliers in sales**\n",
        "\n"
      ],
      "metadata": {
        "id": "ttqaggY9JbDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checking outliers in sales\n",
        "sns.boxplot(rossman_df['Sales'])"
      ],
      "metadata": {
        "id": "hi-4OSfFJfY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removing Outliers Of Sales Column**\n",
        "\n"
      ],
      "metadata": {
        "id": "myTa-13eJp0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#removing outliers\n",
        "def remove_outlier(df_in, col_name):\n",
        "    q1 = df_in[col_name].quantile(0.25)\n",
        "    q3 = df_in[col_name].quantile(0.75)\n",
        "    iqr = q3-q1 #Interquartile range\n",
        "    fence_low  = q1-1.5*iqr\n",
        "    fence_high = q3+1.5*iqr\n",
        "    df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high)]\n",
        "    return df_out"
      ],
      "metadata": {
        "id": "1v2Dcck_Juv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining new variable after removing outliers\n",
        "df= remove_outlier(df, 'Sales')"
      ],
      "metadata": {
        "id": "lZFQtjn9JyrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Conclusion of the analysis:***\n"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Sales are highly correlated to number of Customers.\n",
        "\n",
        "* The most selling and crowded store type is A.\n",
        "\n",
        "* StoreType B has the lowest Average Sales per Customer. So i think customers visit this type only for small things.\n",
        "\n",
        "* StoreTybe D had the highest buyer cart.\n",
        "\n",
        "* Promo runs only in weekdays.\n",
        "\n",
        "* For all stores, Promotion leads to increase in Sales and Customers both.\n",
        "\n",
        "* More stores are opened during School holidays than State holidays.\n",
        "\n",
        "* The stores which are opened during School Holiday have more sales than normal days.\n",
        "\n",
        "* Sales are increased during Chirstmas week, this might be due to the fact that people buy more beauty products during a Christmas celebration.\n",
        "\n",
        "* Promo2 doesnt seems to be correlated to any significant change in the sales amount.\n",
        "\n",
        "* Absence of values in features CompetitionOpenSinceYear/Month doesnâ€™t indicate the absence of competition as CompetitionDistance values are not null where the other two values are null."
      ],
      "metadata": {
        "id": "cb7bgFaQKFHt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Drop Subsets Of Data Where Might Cause Bias***\n"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# where stores are closed, they won't generate sales, so we will remove that part of the dataset\n",
        "df = df[df.Open != 0]"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open isn't a variable anymore, so we'll drop it too\n",
        "df = df.drop('Open', axis=1)"
      ],
      "metadata": {
        "id": "JiIwMJDXK8iV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if there's any opened store with zero sales\n",
        "df[df.Sales == 0]['Store'].sum()"
      ],
      "metadata": {
        "id": "R6tNM9AFK8lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see the percentage of open stored with zero sales\n",
        "df[df.Sales == 0]['Sales'].sum()/df.Sales.sum()"
      ],
      "metadata": {
        "id": "Rw7psUbwK8n0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove this part of data to avoid bias\n",
        "df = df[df.Sales != 0]"
      ],
      "metadata": {
        "id": "CCUEd1XFK8p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new=df.copy()"
      ],
      "metadata": {
        "id": "zHjUEmv9K8tB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = pd.get_dummies(df_new,columns=['StoreType','Assortment'])\n"
      ],
      "metadata": {
        "id": "g0tN4WbLK8vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new.head()\n"
      ],
      "metadata": {
        "id": "h-mmYiA3K8xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From plot it can be sen that most of the sales have been on 1st and last day of week**\n",
        "\n"
      ],
      "metadata": {
        "id": "sInmyWmMLLuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plot for sales in terms of days ofthe week\n",
        "plt.figure(figsize=(15,8))\n",
        "sns.barplot(x='DayOfWeek', y='Sales' ,data=df_new); "
      ],
      "metadata": {
        "id": "vmiJE8hXK80I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Setting Features and Target Variables***\n"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_new.drop(['Sales','Store','Date','Year'] , axis = 1)\n",
        "y= df_new.Sales"
      ],
      "metadata": {
        "id": "4gl-_D6mLZGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape\n"
      ],
      "metadata": {
        "id": "MCJ_OEhBLZIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()\n"
      ],
      "metadata": {
        "id": "AnlU77oGLZKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.head()\n"
      ],
      "metadata": {
        "id": "lN8f6-c4LZMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Splitting Dataset Into Training Set and Test Set**\n"
      ],
      "metadata": {
        "id": "WAEDMI8NLhnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3, random_state=0)\n"
      ],
      "metadata": {
        "id": "zSsBbE_5Lfzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns=X_train.columns\n"
      ],
      "metadata": {
        "id": "DoKMmwZMLf1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***Implementing Supervised Machine Learning algorithms.***\n"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***1. Linear Regression (OLS)***\n"
      ],
      "metadata": {
        "id": "gbpVwcOYLz7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming data\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "M8Z4UlA2Lf3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting Multiple Linear Regression to the Training set\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "75UDbZMULf6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor.intercept_\n"
      ],
      "metadata": {
        "id": "kMOFf5AbL9Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor.coef_\n"
      ],
      "metadata": {
        "id": "nG6vO_3bL9bC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train = regressor.predict(X_train)\n"
      ],
      "metadata": {
        "id": "y6ig_t5AL9dR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the Test set results\n",
        "y_pred = regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "lkWYGSv3L9fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_squared_error(y_test, y_pred)\n"
      ],
      "metadata": {
        "id": "OLrYZ3-KMFqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test performance\n",
        "math.sqrt(mean_squared_error(y_test, y_pred))"
      ],
      "metadata": {
        "id": "YsL75DgHMFsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_score_1=regressor.score(X_train,y_train)\n",
        "train_score_1"
      ],
      "metadata": {
        "id": "TyfD2GkUMFut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_score_1=regressor.score(X_test,y_test)\n",
        "test_score_1"
      ],
      "metadata": {
        "id": "RB2-k5tFMFxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#storing 100 observations for analysis\n",
        "simple_lr_pred = y_pred[:100]\n",
        "simple_lr_real = y_test[:100]\n",
        "dataset_lr = pd.DataFrame({'Real':simple_lr_real,'PredictedLR':simple_lr_pred}) #storing these values into dataframe"
      ],
      "metadata": {
        "id": "NOm1r4W1MF0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#storing absolute diffrences between actual sales price and predicted\n",
        "dataset_lr['diff']=(dataset_lr['Real']-dataset_lr['PredictedLR']).abs()"
      ],
      "metadata": {
        "id": "Wh21eMPUMF4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualising our predictions\n",
        "sns.lmplot(x='Real', y='PredictedLR', data=dataset_lr, line_kws={'color': 'black'});"
      ],
      "metadata": {
        "id": "7wGVxU7JMF6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Inferences On Linear Regression Coefficients***\n"
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = sm.add_constant(X) ## let's add an intercept (beta_0) to our model\n",
        "model = sm.OLS(y, X).fit() ## sm.OLS(output, input)\n",
        "predictions = model.predict(X)\n",
        "\n",
        "# Print out the statistics\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "-wXe9ThCMaRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Warnings:\n",
        "\n",
        "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
        "\n",
        "[2] The smallest eigenvalue is 1.15e-26. This might indicate that there are\n",
        "strong multicollinearity problems or that the design matrix is singular."
      ],
      "metadata": {
        "id": "zUCikIG7Meso"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***2. LARS Lasso Regression***\n"
      ],
      "metadata": {
        "id": "P_XB6amSMjPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "las = LassoLars(alpha=0.3, fit_intercept=False, normalize=True)\n",
        "lasreg = las.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "F0-j74SdMaUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(x, y):\n",
        "    return sqrt(mean_squared_error(x, y))\n",
        "\n",
        "# definte MAPE function\n",
        "def mape(x, y): \n",
        "    return np.mean(np.abs((x - y) / x)) * 100\n",
        "\n",
        "train_score_2=lasreg.score(X_train, y_train)\n",
        "test_score_2=lasreg.score(X_test, y_test)\n",
        "\n",
        "print(\"Regresion Model Score\" , \":\" , train_score_2 , \",\" ,\n",
        "      \"Out of Sample Test Score\" ,\":\" , test_score_2)\n",
        "\n",
        "y_predicted = lasreg.predict(X_train)\n",
        "y_test_predicted = lasreg.predict(X_test)\n",
        "\n",
        "print(\"Training RMSE\", \":\", rmse(y_train, y_predicted),\n",
        "      \"Testing RMSE\", \":\", rmse(y_test, y_test_predicted))\n",
        "print(\"Training MAPE\", \":\", mape(y_train, y_predicted),\n",
        "      \"Testing MAPE\", \":\", mape(y_test, y_test_predicted))"
      ],
      "metadata": {
        "id": "5l_aNI0fMaWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Decision Tree Regression**"
      ],
      "metadata": {
        "id": "pNmbnNx8Mtgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree = DecisionTreeRegressor()\n",
        "treereg = tree.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "_PW9xT3DMaZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_score_3=treereg.score(X_train, y_train)\n",
        "test_score_3=treereg.score(X_test, y_test)\n",
        "\n",
        "print(\"Regresion Model Score\" , \":\" , train_score_3 , \",\" ,\n",
        "      \"Test Score\" ,\":\" , test_score_3)\n",
        "\n",
        "y_predicted = treereg.predict(X_train)\n",
        "y_test_predicted = treereg.predict(X_test)\n",
        "print(\"Training RMSE\", \":\", rmse(y_train, y_predicted),\n",
        "      \"Testing RMSE\", \":\", rmse(y_test, y_test_predicted))\n",
        "print(\"Training MAPE\", \":\", mape(y_train, y_predicted),\n",
        "      \"Testing MAPE\", \":\", mape(y_test, y_test_predicted))"
      ],
      "metadata": {
        "id": "bHtLqL2dMacD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Decision Tree With Hyper Parameter Tuning**\n"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #another script that takes toooo long, to find the right parameters for tree\n",
        "# tree = DecisionTreeRegressor()\n",
        "\n",
        "# params = {\n",
        "#          'min_samples_split':[2,3,5,7],\n",
        "#          'min_samples_leaf':[6,8,10],\n",
        "#          }\n",
        "\n",
        "# grid = RandomizedSearchCV(estimator=rfr,param_distributions=params,verbose=True,cv=10)\n",
        "# #choosing 10 K-Folds makes sure i went through all of the data and didn't miss any pattern.\n",
        "\n",
        "# grid.fit(X_train, y_train)\n",
        "# grid.best_params_"
      ],
      "metadata": {
        "id": "Em8Ryp3qM7kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I trained Model with hyper parameters..to not run everytime i record the result\n",
        "\n",
        "Here are our best parameters for Decision Tree\n",
        "\n",
        "{ min_samples_split=5,min_samples_leaf=8 }"
      ],
      "metadata": {
        "id": "aFUYSvKDNBGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree = DecisionTreeRegressor(min_samples_leaf=8,min_samples_split=5)\n",
        "treereg = tree.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "m0Nmu-WENIsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_score_4=treereg.score(X_train, y_train)\n",
        "test_score_4=treereg.score(X_test, y_test)\n",
        "\n",
        "print(\"Regresion Model Score\" , \":\" , train_score_4 , \",\" ,\n",
        "      \"Test Score\" ,\":\" , test_score_4)\n",
        "\n",
        "y_predicted = treereg.predict(X_train)\n",
        "y_test_predicted = treereg.predict(X_test)\n",
        "print(\"Training RMSE\", \":\", rmse(y_train, y_predicted),\n",
        "      \"Testing RMSE\", \":\", rmse(y_test, y_test_predicted))\n",
        "print(\"Training MAPE\", \":\", mape(y_train, y_predicted),\n",
        "      \"Testing MAPE\", \":\", mape(y_test, y_test_predicted))"
      ],
      "metadata": {
        "id": "pdMS2WqcNIwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#storing 100 observations for analysis\n",
        "dc_pred = y_test_predicted[:100]\n",
        "dc_real = y_test[:100]\n",
        "dataset_dc = pd.DataFrame({'Real':dc_real,'PredictedDC':dc_pred}) #storing these values into dataframe"
      ],
      "metadata": {
        "id": "h_mg3BXZNIy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#storing absolute diffrences between actual sales price and predicted\n",
        "dataset_dc['diff']=(dataset_dc['Real']-dataset_dc['PredictedDC']).abs()"
      ],
      "metadata": {
        "id": "f7TkV7HcNI1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualising our predictions\n",
        "sns.lmplot(x='Real', y='PredictedDC', data=dataset_dc, line_kws={'color': 'black'});"
      ],
      "metadata": {
        "id": "QoYSeXOWNI6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***4. Support Vector Regression***"
      ],
      "metadata": {
        "id": "fjNRY5iENUnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%time\n",
        "#from sklearn.svm import SVR\n",
        "#svr=SVR()\n",
        "#svr_reg=svr.fit(X_train,y_train)\n",
        "#svr\n"
      ],
      "metadata": {
        "id": "gLD8VM9hNI9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(\"Regresion Model Score\" , \":\" , svr_reg.score(X_train, y_train) , \",\" ,\n",
        "#      \"Out of Sample Test Score\" ,\":\" , svr_reg.score(X_test, y_test))\n",
        "\n",
        "#y_predicted = svr_reg.predict(X_train)\n",
        "#y_test_predicted = svr_reg.predict(X_test)\n",
        "\n",
        "#print(\"Training RMSE\", \":\", rmse(y_train, y_predicted),\n",
        "#      \"Testing RMSE\", \":\", rmse(y_test, y_test_predicted))\n",
        "#print(\"Training MAPE\", \":\", mape(y_train, y_predicted),\n",
        "#      \"Testing MAPE\", \":\", mape(y_test, y_test_predicted))"
      ],
      "metadata": {
        "id": "lUdSAmV8NcO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. K-Nearest Neighbors Regression**"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "knn = KNeighborsRegressor(n_neighbors = 30)\n",
        "knnreg = knn.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "jFulqlOpNlpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Random Forest With Hyper Parameter Tuning**+\n",
        "\n"
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #another script that takes toooo long, to find the right parameters for RFR\n",
        "# rfr=RandomForestRegressor(n_jobs=-1)\n",
        "\n",
        "# params = {\n",
        "#          'n_estimators':[40,50,60,70,80,90],\n",
        "#          'min_samples_split':[2,3,6,8],\n",
        "#          'min_samples_leaf':[1,2,3,4],\n",
        "#          'max_depth':[None,5,15,30]\n",
        "#          }\n",
        "\n",
        "# #the dimensionality is high, the number of combinations we have to search is enormous, using RandomizedSearchCV is a better option then GridSearchCV\n",
        "# grid = RandomizedSearchCV(estimator=rfr,param_distributions=params,verbose=True,cv=10)\n",
        "\n",
        "# #choosing 10 K-Folds makes sure i went through all of the data and didn't miss any pattern.\n",
        "# grid.fit(X_train, y_train)\n",
        "# grid.best_params_"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I trained Model with hyper parameters..to not run everytime i record the result\n",
        "\n",
        "Here are our best parameters for Random Forest\n",
        "\n",
        "{ n_estimators=80,min_samples_split=2,min_samples_leaf=1,max_depth=None }"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%time\n",
        "rdf = RandomForestRegressor(n_estimators=80,min_samples_split=2, min_samples_leaf=1,max_depth=None,n_jobs=-1)\n",
        "rdfreg = rdf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "waD4IeFgN9RC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_score_5=rdfreg.score(X_train, y_train)\n",
        "test_score_5=rdfreg.score(X_test, y_test)\n",
        "\n",
        "print(\"Regresion Model Score\" , \":\" , train_score_5 , \",\" ,\n",
        "      \"Test Score\" ,\":\" , test_score_5)   \n",
        "\n",
        "y_predicted_2 = rdfreg.predict(X_train)\n",
        "y_test_predicted_2 = rdfreg.predict(X_test)\n",
        "\n",
        "print(\"Training RMSE\", \":\", rmse(y_train, y_predicted_2),\n",
        "      \"Testing RMSE\", \":\", rmse(y_test, y_test_predicted_2))\n",
        "print(\"Training MAPE\", \":\", mape(y_train, y_predicted_2),\n",
        "      \"Testing MAPE\", \":\", mape(y_test, y_test_predicted_2))"
      ],
      "metadata": {
        "id": "Af4n5sRAN9Uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_predicted_2\n"
      ],
      "metadata": {
        "id": "R02HnGYOODnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#storing 100 observations for analysis\n",
        "rf_prd = y_test_predicted_2[:100]\n",
        "rf_real = y_test[:100]\n",
        "dataset_rf = pd.DataFrame({'Real':rf_real,'PredictedRF':rf_prd})"
      ],
      "metadata": {
        "id": "CFGRhrSaOGZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#storing absolute diffrences between actual sales price and predicted\n",
        "dataset_rf['diff']=(dataset_rf['Real']-dataset_rf['PredictedRF']).abs()"
      ],
      "metadata": {
        "id": "Bnv67LlhOGbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # taking 4 sample\n",
        "dataset_rf.sample(4)"
      ],
      "metadata": {
        "id": "vSLDvcFWOGeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Statistical description of our predictions and actual values \n",
        "dataset_rf.describe()"
      ],
      "metadata": {
        "id": "w79FcjgbOGhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting the actual,predicted & difference of SALES\n",
        "plt.style.use('seaborn')\n",
        "dataset_rf.plot.hist(subplots=True, legend=False);"
      ],
      "metadata": {
        "id": "BBUGoPCkOGj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As we can see that Actual, Prediction values are approximately closed to each other and there is no such significant variation in our plots.**\n",
        "\n"
      ],
      "metadata": {
        "id": "0c2Lp45gOQz8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Importance On Random Forest Regressor**\n"
      ],
      "metadata": {
        "id": "5oFQ92e_OaJI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see that Random Forest has the highest test score\n",
        "\n"
      ],
      "metadata": {
        "id": "eSKxvPqDOeWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_feature_importance(importance,names,model_type):\n",
        "\n",
        "  #Create arrays from feature importance and feature names\n",
        "  feature_importance = np.array(importance)\n",
        "  feature_names = np.array(names)\n",
        "\n",
        "  #Create a DataFrame using a Dictionary\n",
        "  data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
        "  fi_df = pd.DataFrame(data)\n",
        "\n",
        "  #Sort the DataFrame in order decreasing feature importance\n",
        "  fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
        "\n",
        "  #Define size of bar plot\n",
        "  plt.figure(figsize=(10,8))\n",
        "  #Plot Searborn bar chart\n",
        "  sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
        "  #Add chart labels\n",
        "  plt.title(model_type + ' FEATURE IMPORTANCE')\n",
        "  plt.xlabel('FEATURE IMPORTANCE')\n",
        "  plt.ylabel('FEATURE NAMES')"
      ],
      "metadata": {
        "id": "i3-OF9OaOGp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_feature_importance(rdfreg.feature_importances_,columns[:],'RANDOM FOREST')\n"
      ],
      "metadata": {
        "id": "yL42z1rNOiRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Customers, CompetitionDistance, StoreType_d, Promo these four are most important features in our sales prediction.**\n",
        "\n"
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score_df = pd.DataFrame({'Train_Score':[train_score_1,train_score_2,train_score_3,train_score_4,train_score_5],'Test_Score':[test_score_1,test_score_2,test_score_3,test_score_4,test_score_5]},index=['Linear Regression','Lasso Regression','Decision Tree',\"Decision Tree(hyperparameters)\",'Random Forest Regression'])\n"
      ],
      "metadata": {
        "id": "IAr2SiOOOpIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score_df\n"
      ],
      "metadata": {
        "id": "tH33WRpHOwA_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}